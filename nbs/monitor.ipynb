{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "purple-rubber",
   "metadata": {},
   "source": [
    "# Resource usage monitoring\n",
    "\n",
    "Can be done from outside of process - which measures process as a whole, or from inside. Outside is easier, but less precise.\n",
    "\n",
    "[Memory usage](https://medium.com/survata-engineering-blog/monitoring-memory-usage-of-a-running-python-program-49f027e3d1ba) - medium article.\n",
    "\n",
    "\n",
    "Here is a resource monitor class that watches a given process from a subprocess. It uses cross-platform `psutil` package to read process information. I/O stats are not available on MacOS.\n",
    "\n",
    "\n",
    "To test disk I/O speed on Linux:\n",
    "- write: `sync; dd if=/dev/zero of=tempfile bs=1M count=1024; sync`\n",
    "- read: `dd if=tempfile of=/dev/null bs=1M count=1024`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp monitor\n",
    "#export\n",
    "import sys\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "import inspect\n",
    "import warnings\n",
    "import functools\n",
    "\n",
    "import psutil\n",
    "from psutil._common import bytes2human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def usage_log(pid, interval=1):\n",
    "    \"\"\"Regularly write resource usage to stdout.\"\"\"\n",
    "    # local imports make function self-sufficient\n",
    "    import time, psutil\n",
    "\n",
    "    if psutil.MACOS:\n",
    "        warnings.warn('Disk I/O stats are not available on MacOS.')\n",
    "\n",
    "    p = psutil.Process(pid)\n",
    "\n",
    "    def get_io():\n",
    "        if psutil.MACOS:\n",
    "            # io_counters() not available on MacOS\n",
    "            return (0, 0, 0, 0)\n",
    "        elif psutil.WINDOWS:\n",
    "            x = p.io_counters()\n",
    "            return (x.read_bytes, 0, x.write_bytes, 0)\n",
    "        else:\n",
    "            x = p.io_counters()\n",
    "            return (x.read_bytes, x.read_chars, x.write_bytes, x.write_chars)\n",
    "\n",
    "    print('time,cpu,memory,read_bytes,read_chars,write_bytes,write_chars')\n",
    "    p.cpu_percent()\n",
    "    io_before = get_io()\n",
    "    while True:\n",
    "        io_after = get_io()\n",
    "        io_rate = tuple((x1 - x0) / interval for x0, x1 in zip(io_before, io_after))\n",
    "        io_before = io_after\n",
    "        line = (time.time(), p.cpu_percent(), p.memory_info().rss) + io_rate\n",
    "        print(','.join(str(x) for x in line), flush=True)\n",
    "        time.sleep(interval)        \n",
    "    \n",
    "class ResourceMonitor:\n",
    "    def __init__(self, pid=None, interval=1):\n",
    "        self.pid = os.getpid() if pid is None else pid\n",
    "        self.interval = interval\n",
    "        self.tags = []\n",
    "        self.df = None\n",
    "\n",
    "    def start(self):\n",
    "        code = inspect.getsource(usage_log) + f'\\nusage_log({self.pid}, {self.interval})'\n",
    "        self.process = subprocess.Popen([sys.executable, '-c', code], text=True,\n",
    "                                        stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "    def stop(self):\n",
    "        self.process.terminate()\n",
    "        import pandas as pd\n",
    "        log_data = self.process.stdout.read()\n",
    "        if log_data.count('\\n') < 2:\n",
    "            warnings.warn('ResourceMonitor: no entries in monitor log, execution time may be too short.')\n",
    "            return            \n",
    "        df = pd.read_csv(io.StringIO(log_data))\n",
    "        df['elapsed'] = df['time'] - df.loc[0, 'time']\n",
    "        self.df = df.set_index('elapsed')\n",
    "\n",
    "    def tag(self, label):\n",
    "        self.tags.append((time.time(), label))\n",
    "\n",
    "    def plot(self):\n",
    "        if self.df is None:\n",
    "            print('ResourceMonitor: no entries in monitor log, execution time may be too short.')\n",
    "            return\n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # newer versions of mpl show a warning on ax.set_yticklabels()\n",
    "        # other ways to fix the problem:\n",
    "        # https://stackoverflow.com/questions/63723514/userwarning-fixedformatter-should-only-be-used-together-with-fixedlocator\n",
    "        warnings.filterwarnings('ignore', message='FixedFormatter should only be used together with FixedLocator')\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "        ax = axes[0][0]\n",
    "        ax.plot(self.df['cpu'])\n",
    "        ax.set_title('cpu')\n",
    "\n",
    "        ax = axes[1][0]\n",
    "        ax.plot(self.df['memory'])\n",
    "        ax.set_title('memory')\n",
    "        ax.set_yticklabels([bytes2human(x) for x in ax.get_yticks()])\n",
    "\n",
    "        ax = axes[0][1]\n",
    "        ax.plot(self.df['read_bytes'], label='bytes')\n",
    "        ax.plot(self.df['read_chars'], label='chars')\n",
    "        ax.set_title('read')\n",
    "        ax.legend()\n",
    "        ax.set_yticklabels([bytes2human(x) for x in ax.get_yticks()])\n",
    "\n",
    "        ax = axes[1][1]\n",
    "        ax.plot(self.df['write_bytes'], label='bytes')\n",
    "        ax.plot(self.df['write_chars'], label='chars')\n",
    "        ax.set_title('write')\n",
    "        ax.legend()\n",
    "        ax.set_yticklabels([bytes2human(x) for x in ax.get_yticks()])\n",
    "\n",
    "        t0 = self.df.loc[0, 'time']\n",
    "        for ax in axes.flatten():\n",
    "            y = min(l.get_data()[1].min() for l in ax.lines)\n",
    "            for tag in self.tags:\n",
    "                ax.text(tag[0] - t0, y, tag[1], rotation='vertical')\n",
    "\n",
    "    def dump(self, filepath):\n",
    "        d = {'tags': self.tags,\n",
    "             'data': self.df.to_csv()}\n",
    "        json.dump(d, open(filepath, 'w'))\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filepath):\n",
    "        import pandas as pd\n",
    "        d = json.load(open(filepath))\n",
    "        m = cls()\n",
    "        m.tags = d['tags']\n",
    "        m.df = pd.read_csv(io.StringIO(d['data'])).set_index('elapsed')\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "from tempfile import TemporaryFile, NamedTemporaryFile\n",
    "\n",
    "def use_cpu(t):\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < t:\n",
    "        x = 1\n",
    "\n",
    "def use_mem(s, n):\n",
    "    x = []\n",
    "    for _ in range(n):\n",
    "        x += [1] * s * 1_000_000\n",
    "        time.sleep(1)\n",
    "\n",
    "def write(f, size_mb):\n",
    "    size = size_mb * 2**20\n",
    "    count = 0\n",
    "    block_size = 8 * 2**10\n",
    "    data = b'a' * block_size\n",
    "    f.seek(0)\n",
    "    while count < size:\n",
    "        count += f.write(data)\n",
    "        f.flush()\n",
    "\n",
    "def read(f):\n",
    "    block_size = 8 * 2**10\n",
    "    f.seek(0)\n",
    "    while f.peek():\n",
    "        f.read(block_size)\n",
    "\n",
    "mon = ResourceMonitor(interval=0.1)\n",
    "mon.start()\n",
    "time.sleep(2)\n",
    "mon.tag('cpu v')\n",
    "use_cpu(2)\n",
    "mon.tag('cpu ^')\n",
    "time.sleep(1)\n",
    "mon.tag('mem1 v')\n",
    "use_mem(30, 2)\n",
    "mon.tag('mem1 ^')\n",
    "time.sleep(1)\n",
    "mon.tag('mem2 v')\n",
    "use_mem(10, 2)\n",
    "mon.tag('mem2 ^')\n",
    "time.sleep(1)\n",
    "with TemporaryFile() as tf:\n",
    "    mon.tag('write v')\n",
    "    write(tf, 1000)\n",
    "    mon.tag('write ^')\n",
    "    time.sleep(1)\n",
    "    mon.tag('read v')\n",
    "    read(tf)\n",
    "    mon.tag('read ^')\n",
    "time.sleep(1)\n",
    "mon.stop()\n",
    "mon.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST serialization\n",
    "m1 = ResourceMonitor(interval=0.2)\n",
    "m1.start()\n",
    "time.sleep(1)\n",
    "m1.tag('start')\n",
    "use_cpu(2)\n",
    "m1.tag('stop')\n",
    "time.sleep(1)\n",
    "m1.stop()\n",
    "\n",
    "with NamedTemporaryFile() as tf:\n",
    "    m1.dump(tf.name)\n",
    "    m2 = ResourceMonitor.load(tf.name)\n",
    "    m2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca019a-da87-4943-86d3-c07cc7eea1f9",
   "metadata": {},
   "source": [
    "# Decorator for function runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1eb978-5f88-48e9-a04f-a878bf7d5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def func_sig(f, *args, **kwargs):\n",
    "    \"\"\"Return string representing function with argument values.\"\"\"\n",
    "    import pandas as pd\n",
    "    def arg2str(x):\n",
    "        if isinstance(x, pd.Series):\n",
    "            return f'series({len(x)})'\n",
    "        if isinstance(x, pd.DataFrame):\n",
    "            return f'dataframe{df.shape}'\n",
    "        s = str(x)\n",
    "        if len(s) <= 10:\n",
    "            return s\n",
    "        else:\n",
    "            return s[:9] + 'â€¦'\n",
    "    a = []\n",
    "    for v in args:\n",
    "        a.append(arg2str(v))\n",
    "    for k, v in kwargs.items():\n",
    "        a.append(f'{k}={arg2str(v)}')\n",
    "    a = ', '.join(a)\n",
    "    return f'{f.__name__}({a})'\n",
    "\n",
    "def log_start_finish(f):\n",
    "    \"\"\"Print function call signature on start and on finish with total runtime.\"\"\"\n",
    "    @functools.wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        sig = func_sig(f, *args, **kwargs)\n",
    "        t0 = time.time()\n",
    "        print(f'{sig} started.')\n",
    "        res = f(*args, **kwargs)\n",
    "        dt = time.time() - t0\n",
    "        print(f'{sig} finished in {dt:.2f} seconds.')\n",
    "        return res\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb36cf-a594-4728-bdf7-a01797d804f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "@log_start_finish\n",
    "def func(x, d):\n",
    "    time.sleep(0.5)\n",
    "    return x + 1\n",
    "\n",
    "df = pd.DataFrame(index=range(1000), columns=range(5))\n",
    "func(1, d=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c08f6b6-5e6a-4b69-8244-54ae7b5dd024",
   "metadata": {},
   "source": [
    "Also works under multiprocessing, although output can get scrambled if multiple processes try to print at the same time. A more robust solution for multiprocessing can use [logging](https://docs.python.org/3/howto/logging-cookbook.html#logging-to-a-single-file-from-multiple-processes) module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865766dc-8256-4498-ab3d-9ed47d819225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "@log_start_finish\n",
    "def func(x):\n",
    "    time.sleep(0.5 + x/10)\n",
    "    return x + 1\n",
    "\n",
    "with multiprocessing.Pool(2) as pool:\n",
    "    result = pool.map(func, range(4))\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
